{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOkYHO8Kyz7H7E5nTpephoq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"KqbGCG2BFAFs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768851732730,"user_tz":-60,"elapsed":18498,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}},"outputId":"d74dbb61-abe5-4e3c-d713-97e5fa69d17c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVgLfZsPn9y8","executionInfo":{"status":"ok","timestamp":1768851741020,"user_tz":-60,"elapsed":6497,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}},"outputId":"9d90ccb5-1f7a-4d86-c987-ec2c788ca5e2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.4.6-py3-none-any.whl.metadata (38 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n","Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n","Downloading ultralytics-8.4.6-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.4.6 ultralytics-thop-2.0.18\n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","import joblib\n","import torch\n","\n","from skimage.feature import hog\n","from ultralytics import YOLO\n","import torchvision.transforms.functional as F\n"],"metadata":{"id":"0EVKSNNznI7N","executionInfo":{"status":"ok","timestamp":1768852530940,"user_tz":-60,"elapsed":1998,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["# ===== CLASSIFIER =====\n","XGB_MODEL_PATH = \"/content/drive/MyDrive/RF_Val/xgboost_model.json\"\n","LABEL_PATH = \"/content/drive/MyDrive/RF_Val/label_classes.npy\"\n","\n","# ===== DETECTORS =====\n","FASTER_RCNN_PATH = \"/content/drive/MyDrive/fasterrcnn_vivax_aug.pth\"\n","RTDETR_PATH = \"/content/drive/MyDrive/Vivax_data_augmented/vivax_results/train/weights/best.pt\"\n","YOLOV11_PATH = \"/content/drive/MyDrive/weights_vivax_yolo/best.pt\"\n","\n","# ===== DATA =====\n","VAL_DIR = \"/content/drive/MyDrive/Ovale/images/valid\"\n","\n","# ===== OUTPUT =====\n","OUT_FRCNN = \"/content/drive/MyDrive/xgbst_fastercnn\"\n","OUT_RTDETR = \"/content/drive/MyDrive/xgbst_rtdetr\"\n","OUT_YOLO = \"/content/drive/MyDrive/xgbst_yolo\"\n","\n","for d in [OUT_FRCNN, OUT_RTDETR, OUT_YOLO]:\n","    os.makedirs(d, exist_ok=True)\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","IMG_SIZE = 64\n","TARGET_IMG_SIZE = 640 # New constant for consistent image resizing\n","VALID_EXT = (\".png\", \".jpg\", \".jpeg\")"],"metadata":{"id":"XsGZH9BWnlCL","executionInfo":{"status":"ok","timestamp":1768852531017,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["CLASS_NAMES = list(np.load(LABEL_PATH))\n","\n","STAGE_CLASSES = {\n","    1: \"Ring\",\n","    2: \"Trophozoite\",\n","    3: \"Schizont\",\n","    4: \"Gametocyte\"\n","}"],"metadata":{"id":"GzU1OeYLoyOk","executionInfo":{"status":"ok","timestamp":1768852534153,"user_tz":-60,"elapsed":30,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["from xgboost import XGBClassifier\n","\n","xgb_model = XGBClassifier()\n","xgb_model.load_model(XGB_MODEL_PATH)\n","\n","print(\"✅ XGBoost classifier loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"txRfVFTGo--C","executionInfo":{"status":"ok","timestamp":1768852535748,"user_tz":-60,"elapsed":1583,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}},"outputId":"d4a12174-0cf3-4184-9285-3e171ff2508e"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ XGBoost classifier loaded\n"]}]},{"cell_type":"code","source":["def xgb_preprocess(image_path):\n","    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    if img is None:\n","        raise ValueError(f\"Cannot read image: {image_path}\")\n","\n","    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","\n","    features = hog(\n","        img,\n","        orientations=9,\n","        pixels_per_cell=(8, 8),\n","        cells_per_block=(2, 2),\n","        block_norm=\"L2-Hys\"\n","    )\n","    return features.reshape(1, -1)"],"metadata":{"id":"HfheE_oypFaN","executionInfo":{"status":"ok","timestamp":1768852537100,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["def classify_species_xgb(image_path):\n","    features = xgb_preprocess(image_path)\n","    idx = int(xgb_model.predict(features)[0])\n","    confidence = float(xgb_model.predict_proba(features).max())\n","    return CLASS_NAMES[idx], confidence"],"metadata":{"id":"1mIQAnK0pJ6O","executionInfo":{"status":"ok","timestamp":1768852538157,"user_tz":-60,"elapsed":26,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["def draw_species_label(img, species, conf):\n","    label = f\"{species} ({conf:.2f})\"\n","    font, scale, thick = cv2.FONT_HERSHEY_SIMPLEX, 0.9, 3\n","    (w, h), _ = cv2.getTextSize(label, font, scale, thick)\n","\n","    cv2.rectangle(img, (10,10), (10+w+14,10+h+20), (0,255,0), -1)\n","    cv2.putText(img, label, (17,10+h+10), font, scale, (0,0,0), thick, cv2.LINE_AA)\n","    return img"],"metadata":{"id":"KFo2ibCwpNkb","executionInfo":{"status":"ok","timestamp":1768852541130,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","def load_frcnn(path):\n","    model = fasterrcnn_resnet50_fpn(weights=None)\n","    in_feat = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_feat, 5)\n","    model.load_state_dict(torch.load(path, map_location=DEVICE))\n","    model.to(DEVICE).eval()\n","    print(\"✅ Faster R-CNN loaded\")\n","    return model\n","\n","faster_rcnn = load_frcnn(FASTER_RCNN_PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cc6jLf95pQmO","executionInfo":{"status":"ok","timestamp":1768852542383,"user_tz":-60,"elapsed":1001,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}},"outputId":"778a0ee1-e84b-42e1-f213-e759044fc1b0"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Faster R-CNN loaded\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","rtdetr_model = YOLO(RTDETR_PATH)\n","print(\"✅ RT-DETR loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8KWngnZpUZM","executionInfo":{"status":"ok","timestamp":1768852543520,"user_tz":-60,"elapsed":495,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}},"outputId":"4bdcc94e-ca30-45cc-9c68-614e41dcca88"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ RT-DETR loaded\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO\n","yolov11 = YOLO(YOLOV11_PATH)\n","print(\"✅ YOLOv11 loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGjVCHvMpcNO","executionInfo":{"status":"ok","timestamp":1768852548453,"user_tz":-60,"elapsed":61,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}},"outputId":"d3d0e1d4-28b9-4757-c273-497ff47d31de"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ YOLOv11 loaded\n"]}]},{"cell_type":"code","source":["def draw_boxes(img, boxes, labels, scores, label_map, thresh=0.5):\n","    for b, l, s in zip(boxes, labels, scores):\n","        if s < thresh or l not in label_map:\n","            continue\n","        x1,y1,x2,y2 = map(int, b)\n","        txt = f\"{label_map[l]} ({s:.2f})\"\n","\n","        cv2.rectangle(img,(x1,y1),(x2,y2),(0,0,255),3)\n","        (w,h),_ = cv2.getTextSize(txt, cv2.FONT_HERSHEY_SIMPLEX,0.6,2)\n","        cv2.rectangle(img,(x1,y1-h-10),(x1+w+6,y1),(0,0,255),-1)\n","        cv2.putText(img,txt,(x1+3,y1-4),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,255,255),2)\n","    return img"],"metadata":{"id":"UKc6Sp9xpfDX","executionInfo":{"status":"ok","timestamp":1768852549798,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["def run_xgb_frcnn(image_path):\n","    img = cv2.imread(image_path)\n","    species, conf = classify_species_xgb(image_path)\n","    img = draw_species_label(img, species, conf)\n","\n","    if species != \"Uninfected\":\n","        # Convert to tensor and ensure it's FloatTensor to match model weights\n","        tensor = F.to_tensor(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)).to(DEVICE)\n","        with torch.no_grad():\n","            out = faster_rcnn([tensor])[0]\n","        img = draw_boxes(\n","            img,\n","            out[\"boxes\"].cpu().numpy(),\n","            out[\"labels\"].cpu().numpy(),\n","            out[\"scores\"].cpu().numpy(),\n","            STAGE_CLASSES\n","        )\n","\n","    cv2.imwrite(os.path.join(OUT_FRCNN, \"frcnn_\"+os.path.basename(image_path)), img)"],"metadata":{"id":"hwG75jePqKK6","executionInfo":{"status":"ok","timestamp":1768852641216,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["def run_xgb_rtdetr(image_path):\n","    img = cv2.imread(image_path)\n","    species, conf = classify_species_xgb(image_path)\n","    img = draw_species_label(img, species, conf)\n","\n","    if species != \"Uninfected\":\n","        # Resize image for consistent input to the model\n","        img_resized = cv2.resize(img, (TARGET_IMG_SIZE, TARGET_IMG_SIZE))\n","        # Convert resized image (NumPy array, BGR) to PyTorch Tensor (RGB) and add batch dimension\n","        img_rgb_tensor = F.to_tensor(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)).unsqueeze(0).to(DEVICE)\n","        results = rtdetr_model(img_rgb_tensor) # Pass the tensor to the model\n","        for r in results:\n","            img = draw_boxes(\n","                img,\n","                r.boxes.xyxy.cpu().numpy(),\n","                r.boxes.cls.cpu().numpy().astype(int) + 1, # assuming 0-indexed labels, convert to 1-indexed for STAGE_CLASSES\n","                r.boxes.conf.cpu().numpy(),\n","                STAGE_CLASSES\n","            )\n","\n","    cv2.imwrite(os.path.join(OUT_RTDETR, \"rtdetr_\"+os.path.basename(image_path)), img)"],"metadata":{"id":"m5oK2ivdqO0Q","executionInfo":{"status":"ok","timestamp":1768852836109,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["def run_xgb_yolo(image_path):\n","    img = cv2.imread(image_path)\n","    species, conf = classify_species_xgb(image_path)\n","    img = draw_species_label(img, species, conf)\n","\n","    if species != \"Uninfected\":\n","        # Resize image for consistent input to the model\n","        img_resized = cv2.resize(img, (TARGET_IMG_SIZE, TARGET_IMG_SIZE))\n","        # Convert resized image (NumPy array, BGR) to PyTorch Tensor (RGB) and add batch dimension\n","        img_rgb_tensor = F.to_tensor(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)).unsqueeze(0).to(DEVICE)\n","        results = yolov11(img_rgb_tensor) # Pass the tensor to the model\n","        for r in results:\n","            img = draw_boxes(\n","                img,\n","                r.boxes.xyxy.cpu().numpy(),\n","                r.boxes.cls.cpu().numpy().astype(int)+1,\n","                r.boxes.conf.cpu().numpy(),\n","                STAGE_CLASSES\n","            )\n","\n","    cv2.imwrite(os.path.join(OUT_YOLO, \"yolo_\"+os.path.basename(image_path)), img)"],"metadata":{"id":"zaSbalc9qSDF","executionInfo":{"status":"ok","timestamp":1768852840602,"user_tz":-60,"elapsed":23,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}}},"execution_count":67,"outputs":[]},{"cell_type":"code","source":["import torchvision.transforms.functional as F\n","\n","TARGET_IMG_SIZE = 640 # Ensure TARGET_IMG_SIZE is defined here\n","\n","for img_name in os.listdir(VAL_DIR):\n","    if not img_name.lower().endswith(VALID_EXT):\n","        continue\n","\n","    path = os.path.join(VAL_DIR, img_name)\n","\n","    run_xgb_frcnn(path)\n","    run_xgb_rtdetr(path)\n","    run_xgb_yolo(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXWhcCI-qViY","executionInfo":{"status":"ok","timestamp":1768852854505,"user_tz":-60,"elapsed":9000,"user":{"displayName":"Ajoke","userId":"10563520694192304639"}},"outputId":"0e3a550c-28cc-4635-85ae-c647f9c59338"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 640x640 3 Trophozoites, 73.3ms\n","Speed: 0.0ms preprocess, 73.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 Schizont, 12.9ms\n","Speed: 0.0ms preprocess, 12.9ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 5 Trophozoites, 57.9ms\n","Speed: 0.0ms preprocess, 57.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 Ring, 10.6ms\n","Speed: 0.0ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 2 Schizonts, 1 Trophozoite, 52.7ms\n","Speed: 0.0ms preprocess, 52.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","\n","0: 640x640 1 Schizont, 16.7ms\n","Speed: 0.0ms preprocess, 16.7ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ISCtV4Sm0np8"},"execution_count":null,"outputs":[]}]}